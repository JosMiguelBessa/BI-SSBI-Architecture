::Definir a fonte específica dos eventos a serem processados pelo logstash
input 
{
	::Neste caso, o input de dados é feito através de um ficheiro de texto (.txt)
	file
	{
		::Caminho para o ficheiro a processar
		path => "/opt/logstash/bin/radius_logs/radius_three.txt"
		::Definir o tipo de dados dos eventos processados no ficheiro de input
		type => "radiuslogs"
		::Definir por onde começa a leitura do ficheiro (do início ou do fim)
		start_position => "beginning"
		::Verifica se o ficheiro de input já foi processado. Ao definir ignore_older => 0 se o ficheiro já tiver sido processado, não é processado novamente 
		ignore_older => 0
		::Caminho para o ficheiro que faz o tracking dos eventos que já foram processados do ficheiro de input
		sincedb_path => "/opt/logstash/bin/indexes_since_db_track/tproducaoradius2015"
	} 
}
::Bloco relativo à filtragem dos eventos presentes no ficheiro de input
filter 
{
	::grok é uma pattern que permite modular eventos do ficheiro de input (ideal para eventos provenientes de syslog, apache, mysql, webservers)
	grok
	{
		::Em cada iteração o campo message é populado pelos eventos do ficheiro de input	
		::match é utilizado para identificar os diferentes campos que constituem os eventos do ficheiro de input (presentes no campo message)
		::Este primeiro grok é utilizado para verificar se existe Timestamp no evento
		match => ["message","( Timestamp =\s*(%{INT:timestamp})\s*)"]
	}
	
	::Caso exista Timestamp no evento
	if " Timestamp " in [message]
	{
		grok
		{
			match => ["message","((%{DAY}) (%{SYSLOGTIMESTAMP:datelog}) (%{YEAR:year_radius})\s*Acct-Session-Id =\s*(%{GREEDYDATA:acct_session_id})\s*Called-Station-Id =\s*(%{GREEDYDATA:called_station_id})\s*Calling-Station-Id =\s*(%{GREEDYDATA:calling_station_id})\s*Colubris-AVPair =\s*ssid=(%{WORD:colubris_avpair_ssid})\s*Colubris-AVPair =\s*group=(%{GREEDYDATA:colubris_avpair_group})\s*Colubris-AVPair =\s*incoming-vlan-id=(%{GREEDYDATA:colubris_avpair_incoming_vlan_id})\s*Cisco-AVPair =\s*ssid=(%{WORD:cisco_avpair_ssid})\s*Cisco-AVPair =\s*vlan-id=(%{WORD:cisco_avpair_vlan_id})\s*Cisco-AVPair =\s*nas-location=(%{GREEDYDATA:cisco_avpair_nas_location})\s*User-Name =\s*(%{GREEDYDATA:username})\s*Cisco-AVPair\s*=\s*connect-progress=(%{GREEDYDATA:cisco_avpair_connect_progress})\s*Acct-Status-Type =\s*(%{USERNAME:acct_status_type})\s*NAS-IP-Address =\s*(%{IP:nas_ip_address})\s*NAS-Port-Type =\s*(%{HOSTNAME:nas_port_type})\s*NAS-Port-Id =\s*(%{GREEDYDATA:nas_port_id})\s*NAS-Port =\s*(%{INT:nas_port})\s*WISPr-Location-Name =\s*(%{GREEDYDATA:wispr_location_name})\s*Service-Type =\s*(%{USERNAME:service_type})\s*Acct-Delay-Time =\s*(%{INT:acct_delay_time})\s*Acct-Unique-Session-Id =\s*(%{HOSTNAME:acct_unique_session_id})\s*Acct-Input-Octets =\s*(%{INT:acct_input_octets})\s*Acct-Output-Octets =\s*(%{INT:acct_output_octets})\s*Acct-Input-Packets =\s*(%{INT:acct_input_packets})\s*Acct-Output-Packets =\s*(%{INT:acct_output_packets})\s*Acct-Terminate-Cause =\s*(%{USERNAME:acct_terminate_cause})\s*Cisco-AVPair =\s*disc-cause-ext=(%{GREEDYDATA:cisco_avpair_disc_cause_ext})\s*Stripped-User-Name =\s*(%{GREEDYDATA:stripped_user_name})\s*Realm =\s*(%{USERNAME:realm})\s*Operator-Name =\s*(%{USERNAME:operator_name})\s*Eduroam-SP-Country =\s*(%{USERNAME:eduroam_sp_country})\s*Proxy-State =\s*(%{GREEDYDATA:proxy_state})\s*Cisco-AVPair =\s*auth-algo-type=(%{USERNAME:cisco_avpair_auth_algo_type})\s*Acct-Session-Time =\s*(%{INT:acct_session_time})\s*Acct-Authentic =\s*(%{USERNAME:acct_authentic})\s*Cisco-NAS-Port =\s*(%{GREEDYDATA:cisco_nas_port})\s*Attr-103 =\s*(%{GREEDYDATA:attr_103})\s*Access-Point-Id =\s*(%{INT:access_point_id})\s*Access-Point-Name =\s*(%{GREEDYDATA:access_point_name})\s*Connect-Info =\s*(%{GREEDYDATA:connect_info})\s*Framed-IP-Address =\s*(%{GREEDYDATA:framed_ip_address})\s*NAS-Identifier =\s*(%{GREEDYDATA:nas_identifier})\s*Airespace-Wlan-Id =\s*(%{GREEDYDATA:airespace_wlan_id})\s*Tunnel-Type:%{INT:tunnel_type_int} =\s*(%{GREEDYDATA:tunnel_type})\s*Tunnel-Medium-Type:%{INT:tunnel_medium_type_int} =\s*(%{GREEDYDATA:tunnel_medium_type})\s*Tunnel-Private-Group-Id:%{INT:tunnel_private_group_int} =\s*(%{GREEDYDATA:tunnel_private_group_id})\s*Framed-IPv6-Prefix =\s*(%{GREEDYDATA:framed_ipv6_prefix})\s*Acct-Input-Gigawords =\s*(%{GREEDYDATA:acct_input_gigawords})\s*Acct-Output-Gigawords =\s*(%{GREEDYDATA:acct_output_gigawords})\s*Cisco-AVPair =\s*audit-session-id=(%{WORD:cisco_avpair_audit_session_id})\s*Acct-Multi-Session-Id =\s*(%{GREEDYDATA:acct_multi_session_id})\s*Huawei-Connect-ID =\s*(%{GREEDYDATA:huawei_connect_id})\s*Huawei-Input-Burst-Size =\s*(%{GREEDYDATA:huawei_input_burst_size})\s*Huawei-Input-Average-Rate =\s*(%{GREEDYDATA:huawei_input_average_rate})\s*Huawei-Output-Burst-Size =\s*(%{GREEDYDATA:huawei_output_burst_size})\s*Huawei-Output-Average-Rate =\s*(%{GREEDYDATA:huawei_output_average_rate})\s*Huawei-Priority =\s*(%{GREEDYDATA:huawei_priority})\s*FreeRADIUS-Acct-Session-Start-Time =\s*(%{GREEDYDATA:free_radius_acct_session})\s*Aruba-Essid-Name =\s*(%{GREEDYDATA:aruba_essid_name})\s*Aruba-Location-Id =\s*(%{GREEDYDATA:aruba_location_id})\s*Aruba-AP-Group =\s*(%{GREEDYDATA:aruba_ap_group})\s*Aruba-User-Vlan =\s*(%{GREEDYDATA:aruba_user_vlan})\s*Timestamp =\s*(%{INT:timestamp})\s*Event-Timestamp =\s*(%{GREEDYDATA:event_timestamp}))"]
		}
		
		::Mutate permite fazer alterações a variáveis (criar novos campos, apagar campos, mudar tipo de dados de campos)
		mutate
		{
			::add_field é utilizado para criar um novo campo
			add_field => ["datalog", "%{datelog} %{year_radius}"]
		}
		
		::date é utilizado para definir campos do tipo data
		date
		{
			::Atribuir um formato de data ao campo com os dados referentes à data dos eventos do ficheiro de input
			match => ["datalog", "MMM dd HH:mm:ss YYYY", "MMM d HH:mm:ss YYYY"]
			::Definir a variável do tipo data que será usada no futuro para filtrar eventos num espaço temporal
			target => "@datalog"
			::Definir timezone da data dos eventos do ficheiro de input
			timezone => "UTC"
		}
	}
	
	::Caso não exista timestamp no evento
	else
	{
		grok
		{
			match => ["message","((%{DAY}) (%{SYSLOGTIMESTAMP:datelog}) (%{YEAR:year_radius})\s*Acct-Session-Id =\s*(%{GREEDYDATA:acct_session_id})\s*Called-Station-Id =\s*(%{GREEDYDATA:called_station_id})\s*Calling-Station-Id =\s*(%{GREEDYDATA:calling_station_id})\s*Colubris-AVPair =\s*ssid=(%{WORD:colubris_avpair_ssid})\s*Colubris-AVPair =\s*group=(%{GREEDYDATA:colubris_avpair_group})\s*Colubris-AVPair =\s*incoming-vlan-id=(%{GREEDYDATA:colubris_avpair_incoming_vlan_id})\s*Cisco-AVPair =\s*ssid=(%{WORD:cisco_avpair_ssid})\s*Cisco-AVPair =\s*vlan-id=(%{WORD:cisco_avpair_vlan_id})\s*Cisco-AVPair =\s*nas-location=(%{GREEDYDATA:cisco_avpair_nas_location})\s*User-Name =\s*(%{GREEDYDATA:username})\s*Cisco-AVPair\s*=\s*connect-progress=(%{GREEDYDATA:cisco_avpair_connect_progress})\s*Acct-Status-Type =\s*(%{USERNAME:acct_status_type})\s*NAS-IP-Address =\s*(%{IP:nas_ip_address})\s*NAS-Port-Type =\s*(%{HOSTNAME:nas_port_type})\s*NAS-Port-Id =\s*(%{GREEDYDATA:nas_port_id})\s*NAS-Port =\s*(%{INT:nas_port})\s*WISPr-Location-Name =\s*(%{GREEDYDATA:wispr_location_name})\s*Service-Type =\s*(%{USERNAME:service_type})\s*Acct-Delay-Time =\s*(%{INT:acct_delay_time})\s*Acct-Unique-Session-Id =\s*(%{HOSTNAME:acct_unique_session_id})\s*Acct-Input-Octets =\s*(%{INT:acct_input_octets})\s*Acct-Output-Octets =\s*(%{INT:acct_output_octets})\s*Acct-Input-Packets =\s*(%{INT:acct_input_packets})\s*Acct-Output-Packets =\s*(%{INT:acct_output_packets})\s*Acct-Terminate-Cause =\s*(%{USERNAME:acct_terminate_cause})\s*Cisco-AVPair =\s*disc-cause-ext=(%{GREEDYDATA:cisco_avpair_disc_cause_ext})\s*Stripped-User-Name =\s*(%{GREEDYDATA:stripped_user_name})\s*Realm =\s*(%{USERNAME:realm})\s*Operator-Name =\s*(%{USERNAME:operator_name})\s*Eduroam-SP-Country =\s*(%{USERNAME:eduroam_sp_country})\s*Proxy-State =\s*(%{GREEDYDATA:proxy_state})\s*Cisco-AVPair =\s*auth-algo-type=(%{USERNAME:cisco_avpair_auth_algo_type})\s*Acct-Session-Time =\s*(%{INT:acct_session_time})\s*Acct-Authentic =\s*(%{USERNAME:acct_authentic})\s*Cisco-NAS-Port =\s*(%{GREEDYDATA:cisco_nas_port})\s*Attr-103 =\s*(%{GREEDYDATA:attr_103})\s*Access-Point-Id =\s*(%{INT:access_point_id})\s*Access-Point-Name =\s*(%{GREEDYDATA:access_point_name})\s*Connect-Info =\s*(%{GREEDYDATA:connect_info})\s*Framed-IP-Address =\s*(%{GREEDYDATA:framed_ip_address})\s*NAS-Identifier =\s*(%{GREEDYDATA:nas_identifier})\s*Airespace-Wlan-Id =\s*(%{GREEDYDATA:airespace_wlan_id})\s*Tunnel-Type:%{INT:tunnel_type_int} =\s*(%{GREEDYDATA:tunnel_type})\s*Tunnel-Medium-Type:%{INT:tunnel_medium_type_int} =\s*(%{GREEDYDATA:tunnel_medium_type})\s*Tunnel-Private-Group-Id:%{INT:tunnel_private_group_int} =\s*(%{GREEDYDATA:tunnel_private_group_id})\s*Framed-IPv6-Prefix =\s*(%{GREEDYDATA:framed_ipv6_prefix})\s*Acct-Input-Gigawords =\s*(%{GREEDYDATA:acct_input_gigawords})\s*Acct-Output-Gigawords =\s*(%{GREEDYDATA:acct_output_gigawords})\s*Cisco-AVPair =\s*audit-session-id=(%{WORD:cisco_avpair_audit_session_id})\s*Acct-Multi-Session-Id =\s*(%{GREEDYDATA:acct_multi_session_id})\s*Huawei-Connect-ID =\s*(%{GREEDYDATA:huawei_connect_id})\s*Huawei-Input-Burst-Size =\s*(%{GREEDYDATA:huawei_input_burst_size})\s*Huawei-Input-Average-Rate =\s*(%{GREEDYDATA:huawei_input_average_rate})\s*Huawei-Output-Burst-Size =\s*(%{GREEDYDATA:huawei_output_burst_size})\s*Huawei-Output-Average-Rate =\s*(%{GREEDYDATA:huawei_output_average_rate})\s*Huawei-Priority =\s*(%{GREEDYDATA:huawei_priority})\s*FreeRADIUS-Acct-Session-Start-Time =\s*(%{GREEDYDATA:free_radius_acct_session})\s*Aruba-Essid-Name =\s*(%{GREEDYDATA:aruba_essid_name})\s*Aruba-Location-Id =\s*(%{GREEDYDATA:aruba_location_id})\s*Aruba-AP-Group =\s*(%{GREEDYDATA:aruba_ap_group})\s*Aruba-User-Vlan =\s*(%{GREEDYDATA:aruba_user_vlan})\s*Timestamp =\s*(%{INT:timestamp})\s*Event-Timestamp =\s*(%{GREEDYDATA:event_timestamp}))"]
		}	
		
		mutate
		{
			add_field => ["datalog", "%{datelog} %{year_radius}"]
		}
		
		date
		{
			match => ["datalog", "MMM dd HH:mm:ss YYYY", "MMM d HH:mm:ss YYYY"]
			target => "@datalog"
			timezone => "UTC"
		}
		
	}
	
	::Todos os ficheiros que serão processados foram populados no final com a palavra END 
	::Assim que seja encontrado um evento apenas com a palavra END, termina o processamento
	if "END" in [message]
	{
		mutate
		{
			::adicionar a seguinte tag caso esteja terminado o processamento do ficheiro de input
			add_tag => ["end"]
			::remover a tag que é criada quando o processamento de eventos dá erro (evento não corresponde com o filtro grok)
			remove_tag => ["_grokparsefailure"]
			::remover a tag que é criada quando o processamento de eventos dá erro (formato da data do evento não corresponde ao formato de data definido no filtro)
			remove_tag => ["_dateparsefailure"]
		}
	}
}
::Definir o destino para onde será enviado o resultado do processamento dos eventos (documento) 
::presentes no ficheiro de input (Parte final da pipeline dos eventos)
output 
{
	::Caso exista a tag "end" 
	if "end" in [tags]
	{
		::exec para executar um bash script
		::Neste caso o bash script irá avisar na linha de comandos quando o processamento de eventos estiver concluído
		exec
		{
			::dentro do exec é utilizado o command que leva como parametro uma string. Para que o ficheiro seja executado, devera ser colocado o tipo do 
			::ficheiro a executar antes do caminho do ficheiro
			command => "sh /opt/logstash/bin/stop_filter.sh"
		}
	}
	::Caso exista a tag "_grokparsefailure"
	else if "_grokparsefailure" in [tags]
	{
		::O destino do documento será uma base de dados Elasticsearch
		elasticsearch
		{
			::Utilizado para especificar a ação a tomar sobre a base de dados Elasticsearch 
			::Neste caso será feita uma indexação de documentos
			action => "index"
			::Utilizado para especificar o host/hosts onde se encontra a base de dados onde será armazenado o documento
			hosts => "localhost"
			::Utilizado para especificar a base de dados onde o documento será indexado
			index => "radiuserror"
		}
	}
	
	else
	{
		elasticsearch
		{
			action => "index"
			hosts => "localhost"
			index => "radius-%{+MM.2015}"
			::Permite especificar o caminho para o ficheiro onde é definido um template para os campos do documento a indexar 
			::(definir tipos de dados, se são analizados antes de indexar,...)
			template => ["/opt/logstash/bin/radiustemplate.json"]
			::Utilizado para validar um template customizado para o documento a indexar
			manage_template => true
			::Permite especificar que o template definido anteriormente será sobreposto a qualquer outro
			template_overwrite => true
		}
	}
	
	::Utilizado para imprimir na consola o processamento dos eventos do ficheiro de input, para que o utilizador possa fazer
	::o acompanhamento visual da execução do processo
	stdout
	{
		codec => rubydebug
	}
}
